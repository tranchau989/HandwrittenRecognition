{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNqGzYSAExl_"
      },
      "source": [
        "# MNIST Multi-Modal Learning Practice Notebook\n",
        "\n",
        "In this notebook, you will practice some of the core concepts we have presented. The overall pipeline is as follows:\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Data Preparation\n",
        "\n",
        "- Load the **MNIST** dataset.\n",
        "- Split the dataset into **train**, **validation**, and **test** sets.\n",
        "- Horizontally split each image into **upper** and **lower** halves.\n",
        "- Pad the removed half with zeros to maintain consistent input shapes.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Model Definitions\n",
        "\n",
        "Define three encoders:\n",
        "\n",
        "1. **CNNEncoder**  \n",
        "   - A simple CNN with two convolutional layers and pooling layers.\n",
        "\n",
        "2. **MLPEncoder**  \n",
        "   - A simple MLP with two fully connected layers.\n",
        "\n",
        "3. **FusedModel**  \n",
        "   - A combined model using:\n",
        "     - `CNNEncoder` for the **upper half**.\n",
        "     - `MLPEncoder` for the **lower half**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Training and Evaluation\n",
        "\n",
        "For each encoder:\n",
        "\n",
        "### (i) CNNEncoder\n",
        "\n",
        "- Use only the **upper half** of the input data.\n",
        "- Train for **5 epochs**.\n",
        "- Validate using the validation set.\n",
        "- Evaluate performance on the test set.\n",
        "\n",
        "### (ii) MLPEncoder\n",
        "\n",
        "- Use only the **lower half** of the input data.\n",
        "- Train for **5 epochs**.\n",
        "- Validate using the validation set.\n",
        "- Evaluate performance on the test set.\n",
        "\n",
        "### (iii) FusedModel\n",
        "\n",
        "- Use **both upper and lower halves** of the input data.\n",
        "- Use the CNNEncoder (upper half) and the MLPEncoder (bottom half) and use concatenation to fuse the representations.\n",
        "- Train for **5 epochs**.\n",
        "- Validate using the validation set.\n",
        "- Evaluate performance on the test set.\n",
        "\n",
        "### (iv) Different Fusion Stategies\n",
        "- Explore alternative fusion strategies such as for instance average fusion (Averaging representations).\n",
        "\n",
        "### (v) Investigate how adding noise to the representations impacts performance\n",
        "- Add increasing amounts of noise to one or both modalities and monitor performance.\n",
        "- Visualize the fused representations using PCA or t-SNE.\n",
        "\n",
        "---\n",
        "Concepts introduced tomorrow:\n",
        "\n",
        "### (vi) Self-supervised:\n",
        "- Instead of directly fusing modalities, align the modalities using CLIP.\n",
        "- Visualize the fused representations using PCA or t-SNE.\n",
        "- Train a linear classifier on-top of the learned representations (keeping the encoders frozen).\n",
        "\n",
        "### (vii) Alignment noise:\n",
        "- Add increasing amounts of noise to one or both modalities and monitor performance.\n",
        "- Visualize the fused representations using PCA or t-SNE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZSJS417JBMt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA2VUQ7pDmbu"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B3bQzJZLzL3T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qInXFkhcDnI_"
      },
      "source": [
        "# Set hyperparams and load, split MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ekrUg287zoED"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:30<00:00, 320kB/s] \n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 191kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:04<00:00, 388kB/s] \n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 119kB/s]\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "num_epochs = 5\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "# Load MNIST dataset\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [0.7, 0.3])\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN8RM6hTDx7m"
      },
      "source": [
        "# Visualize some images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FTQYoTcZ1HrZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for images, _ in train_loader:\n",
        "    # Visualize the first few images in the batch\n",
        "    num_images_to_show = 5\n",
        "    for i in range(num_images_to_show):\n",
        "        image = images[i]  # Get one image from the batch\n",
        "        image = np.transpose(image, (1, 2, 0))  # Rearrange dimensions from CxHxW to HxWxC\n",
        "\n",
        "        # Display the image\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')  # Turn off axis labels\n",
        "        plt.show()\n",
        "\n",
        "    break  # Exit the loop after visualizing the first batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJnnL37-D2ct"
      },
      "source": [
        "# Define our models - a CNN, an MLP, and a FusedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flcfL5cAzrDC"
      },
      "outputs": [],
      "source": [
        "class CNNEncoder(nn.Module):\n",
        "    \"\"\"Simple CNN Encoder\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64*7*7, 10) #This shape depends on the kernels and the input (split) shape\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"Simple 2-Layer MLP\"\"\"\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.fc1(x.view(x.size(0), -1))) #Flatten all dimensions except batch_size\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Fusing representations\n",
        "class FusedModel(nn.Module):\n",
        "    #Implement this in practical\n",
        "    \"\"\"Model that fuses CNN and MLP representations.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(FusedModel, self).__init__()\n",
        "        # FILL IN HERE\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # FILL IN HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYxUVujeECJs"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUpLf1EvzuXZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def prepare_data(data):\n",
        "    \"\"\"Splits MNIST images into two halves horizontally and pads to original shape.\"\"\"\n",
        "    upper_half = data[:, :, :14, :]  # Top half: [B, 1, 14, 28]\n",
        "    lower_half = data[:, :, 14:, :]  # Bottom half: [B, 1, 14, 28]\n",
        "\n",
        "    # Pad bottom 14 rows with zeros for upper_half\n",
        "    upper_half_padded = F.pad(upper_half, pad=(0, 0, 0, 14))  # Pad rows: (left, right, top, bottom)\n",
        "\n",
        "    # Pad top 14 rows with zeros for lower_half\n",
        "    lower_half_padded = F.pad(lower_half, pad=(0, 0, 14, 0))  # Pad rows: (left, right, top, bottom)\n",
        "\n",
        "    return upper_half_padded, lower_half_padded\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module, data_loader, optimizer: optim.Optimizer, criterion: nn.modules.loss._Loss):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # FILL IN HERE\n",
        "\n",
        "\n",
        "def evaluate_model(model: nn.Module, data_loader, criterion):\n",
        "    \"\"\"Evaluate the model.\"\"\"\n",
        "    # FILL IN HERE (compute validation and test loss and accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN25tug51MFK"
      },
      "outputs": [],
      "source": [
        "for images, _ in train_loader:\n",
        "  upper_half, lower_half = prepare_data(images)\n",
        "  print(upper_half.shape, lower_half.shape)\n",
        "  print(images.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKNhzJQNEHTF"
      },
      "source": [
        "# Check that split works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_9UNU7315Qo"
      },
      "outputs": [],
      "source": [
        "#Look at the first upper_half image\n",
        "image = upper_half[0]  # Get one image from the batch\n",
        "image = np.transpose(image, (1, 2, 0))  # Rearrange dimensions from CxHxW to HxWxC\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XABlOAXS2Lul"
      },
      "outputs": [],
      "source": [
        "#Look at the first lower_half image\n",
        "image = lower_half[0]  # Get one image from the batch\n",
        "image = np.transpose(image, (1, 2, 0))  # Rearrange dimensions from CxHxW to HxWxC\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciimlk8R2Wtr"
      },
      "outputs": [],
      "source": [
        "#look at first full image\n",
        "image = images[0]\n",
        "image = np.transpose(image, (1, 2, 0))  # Rearrange dimensions from CxHxW to HxWxC\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edplWa04ELkg"
      },
      "source": [
        "# Init and train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as_g7BSFz0PU"
      },
      "outputs": [],
      "source": [
        "#Initialize CNN\n",
        "cnn_encoder = CNNEncoder()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "cnn_optimizer = optim.Adam(cnn_encoder.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfp3nPJzz21t"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the CNN encoder\n",
        "for epoch in range(num_epochs):\n",
        "    train_model(cnn_encoder, train_loader, cnn_optimizer, criterion)\n",
        "    print(f\"Epoch {epoch+1}: CNN Encoder val loss {evaluate_model(cnn_encoder, val_loader, criterion)}\")\n",
        "\n",
        "print(\"Done training! Evaluating on test set...\")\n",
        "#Test\n",
        "evaluate_model(cnn_encoder, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvNUOossEOKJ"
      },
      "source": [
        "# Init and train MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut8P-NWF7U-n"
      },
      "outputs": [],
      "source": [
        "#Initialize MLP\n",
        "mlp = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "mlp_optimizer = optim.Adam(mlp.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train and evaluate the MLP\n",
        "for epoch in range(num_epochs):\n",
        "    train_model(mlp, train_loader, mlp_optimizer, criterion)\n",
        "    print(f\"Epoch {epoch+1}: MLP val loss {evaluate_model(mlp, val_loader, criterion)}\")\n",
        "\n",
        "print(\"Done training! Evaluating on test set...\")\n",
        "#Test\n",
        "evaluate_model(mlp, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FWvHH5fEQch"
      },
      "source": [
        "# Init and train FusedModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAPrwScO7X-r"
      },
      "outputs": [],
      "source": [
        "#Initialize Fusion Encoder\n",
        "fused_nn = FusedModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "fuse_optimizer =  optim.Adam(fused_nn.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxzCNfMB7m8y"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the Fused encoder\n",
        "for epoch in range(num_epochs):\n",
        "    train_model(fused_nn, train_loader, fuse_optimizer, criterion)\n",
        "    print(f\"Epoch {epoch+1}: Fusion Encoder val loss {evaluate_model(fused_nn, val_loader, criterion)}\")\n",
        "\n",
        "print(\"Done training! Evaluating on test set...\")\n",
        "#Test\n",
        "evaluate_model(fused_nn, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDTcxnS2KEDv"
      },
      "source": [
        "## (iv) Different Fusion Stategies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiDpuDoBJimr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Exlo5W6s8Zl"
      },
      "source": [
        "## (v) Investigate how adding noise to the representations impacts performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQvEExABKmtT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9xjVx0utU4K"
      },
      "source": [
        "## (vi) Self-supervised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsGQS_61tZek"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh12pnmItZzI"
      },
      "source": [
        "## (vii) Alignment noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxJ0-c5TtZ_C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nora2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
